---
title: "STA 440 Case 4: Root Growth"
author: "Yura Heo, Anirudh Jain, Richard Jiang"
date: "`r format(Sys.Date(), '%B %d, %Y')`"
format: 
  pdf:
    documentclass: article
    fontsize: 11pt
geometry: margin=1in
header-includes:
  - \usepackage{float}
execute: 
  warning: false
  message: false
  echo: false
---

```{r}
library(dplyr)
library(stringr)
library(tibble)
library(ggplot2)
library(mice)
library(coda)
library(janitor)
library(nlme)
library(broom)
library(knitr)
library(tidyverse)
library(naniar)


posterior_summary <- readRDS("results/posterior_summary.rds")
posterior_samples <- readRDS("results/posterior_samples_jags.rds")
```

# Background and Motivation

Researchers developed a new stroke awareness program with the goal of reducing the time needed to provide patients with life-saving acute stroke care delivery. The investigation was divided into two time periods: the pre-treatment period, during which researchers developed the program, and the program implementation period, which overlapped with the onset of the COVID-19 pandemic. The goals of the investigation are twofold: to determine the factors associated with “good” stroke care outcomes, defined as a discharge to home or a rehabilitation facility, and to determine if the implementation of the program improved patient outcomes.

# Data and Exploratory Data Analysis

The researchers tracked stroke patient data from 2019-2020 on a quarterly basis, recording a variety of covariate variables, patient demographic information, and the hospital site where treatment took place. The resulting data set had missing data: therefore, it was necessary for us to develop an approach to handling the missingness before creating any models. In the exploratory analysis phase, we sought to first determine if data missingness was missing at random, missing completely at random, or missing not at random. Our findings on data missingness were used to inform our approach to creating an appropriate model for patient outcomes. Because one goal of the investigation is to determine the effectiveness of the program implementation relative to pre-implementation, we divided the time into three periods: a baseline period (Y1Q1-Y1Q2), a middle transition period as the program was first implemented (Y1Q3-Y2Q2), and the final implementation period (Y2Q3-Y2Q4), where the effects of the program might be the most detectable. 

To begin our analysis, we first sought to determine which variables were most frequently missing. Figure 1 reveals that the 4 variables with missing data were, in descending order, patient age, whether the patient was transported to the hospital via car or EMS, if the hospital was notified prior to patient arrival if they were transported by EMS, and patient race. To determine whether the data is missing completely at random, we investigated whether there were patterns to the missingness. Figures 2 and 3 are heatmaps visualizing the proportion of data missing from the variables. Figure 2 displays the proportion of missingness in each variable by our three time periods, while Figure 3 displays variable missingness by hospital site. Inspection of Figure 2 reveals that data missingness appears worse for certain time quarters, most severely with missing age in the first period. Figure 3 reveals that certain hospitals, namely site IDs 140, 150, and 170, had high variable missingness, with age being the most frequently missing.



# Model Rationale and Implementation

### Model Rationale
We factor the joint distribution as

$$
\begin{aligned}
p(\text{age},\text{notify},\text{transport},\text{race},\text{home}\mid \mathbf{z})
&= p(\text{home}\mid\text{age},\text{notify},\text{transport},\text{race},\mathbf{z})\\
&\quad\times p(\text{age}\mid\text{notify},\text{transport},\mathbf{z})\\
&\quad\times p(\text{notify}\mid\text{transport},\mathbf{z})\\
&\quad\times p(\text{transport}\mid\mathbf{z})\\
&\quad\times p(\text{race}\mid\text{site}).
\end{aligned}
$$

with $\mathbf{z}$ the fully observed covariates (site, time stage, gender). This ordering mirrors the care workflow (arrival/notification precedes discharge) and lets us impute missing Age/notify/transport inside the MCMC rather than as a preprocessing step. Time is collapsed into three stages: baseline (Y1Q1–Y1Q2), mid (Y1Q3–Y2Q2), final (Y2Q3–Y2Q4) in order to stabilize time effects and reflect the program rollout. Site-level random intercepts allow modest heterogeneity across centers. Fixed effects use weakly informative $\mathcal{N}(0,10^4)$ priors; variance components use half-uniform priors; and site-specific race probabilities follow a Dirichlet($\tfrac12,\tfrac12,\tfrac12$) prior.

### Model Implementation

1. **Outcome (home vs. other):** $\text{home}_i \sim \text{Bernoulli}(p_i)$

$$
\begin{aligned}
\operatorname{logit}(p_i) &= \beta_0 + \beta_{\text{age}}\text{Age}_i + \beta_{\text{gender}}\text{Gender}_i
+ \beta_{\text{ems}}\text{Transport}_i + \beta_{\text{not}}\text{Notify}_i + \beta_{\text{tpa}}\text{TPA}_i \\
&\quad + \beta_{\text{thr}}\text{Thromb}_i + \beta_{\text{tpaC}}\text{TPAComp}_i + \beta_{\text{thrC}}\text{ThrComp}_i
+ \beta_{\text{time}}[t_i] + \beta_{\text{race}}[r_i] + u^{(out)}_{\text{site}[i]}.
\end{aligned}
$$

2. **Age $\mid$ transport, notify, site, time stage, gender**
$$
\text{Age}_i\sim\mathcal{N}\big(\alpha_0 + \alpha_{\text{time}}[t_i] + \alpha_{\text{gender}}\,\text{Gender}_i + \alpha_{\text{tr}}\,\text{Transport}_i + \alpha_{\text{not}}\,\text{Notify}_i + u^{(age)}_{\text{site}[i]},\,\sigma^2_{\text{age}}\big).
$$

3. **Notify $\mid$ transport, site, time stage, gender**
$$
\text{Notify}_i\sim\text{Bernoulli}(\pi^{(not)}_i),\quad \operatorname{logit}(\pi^{(not)}_i)=\delta_0 + \delta_{\text{tr}}\,\text{Transport}_i + \delta_{\text{time}}[t_i] + \delta_{\text{gender}}\,\text{Gender}_i + u^{(not)}_{\text{site}[i]}.
$$

4. **Transport $\mid$ site, time stage, gender**
$$
\text{Transport}_i\sim\text{Bernoulli}(\pi^{(tr)}_i),\quad \operatorname{logit}(\pi^{(tr)}_i)=\gamma_0 + \gamma_{\text{time}}[t_i] + \gamma_{\text{gender}}\,\text{Gender}_i + u^{(tr)}_{\text{site}[i]}.
$$

5. **Race $\mid$ site**
$$
\text{Race}_i\sim\text{Categorical}\big(\pi^{(race)}_{\text{site}[i],\cdot}\big),\quad \pi^{(race)}_{s,\cdot}\sim\text{Dirichlet}\big(\tfrac12,\tfrac12,\tfrac12\big).
$$

Time-stage effects are deviations from the baseline stage (fixed to zero); site random effects are mean-zero Normals with their own scale parameters. We run 3 chains with 2,000 burn-in iterations and 8,000 post–burn-in draws.

### Model Evaluation

We assessed convergence and fit using multiple diagnostics:

- **Trace plots and effective sample sizes**: Core parameters (age, EMS, TPA, complications, time-stage effects, site SDs) show well-mixed “fuzzy caterpillars” with effective sample sizes in the hundreds to thousands, indicating good mixing despite the hierarchical structure (see @fig-trace and @tbl-ess).

- **Gelman–Rubin (R-hat)**: All substantive parameters have PSRFs $\approx$ 1.00–1.02; race and time-stage effects mix well despite small subgroup sizes. Intercept and age show mild autocorrelation but remain below typical concern thresholds (upper CI $\approx$ 1.04); see @tbl-rhat.

- **Posterior predictive checks**: Residuals split by outcome behave as expected for binary data; Pearson residuals only spike when the model was highly confident and the outcome disagreed. The Bayesian calibration curve tracks the diagonal closely, with only slight under-prediction in mid–high probability bins, indicating well-calibrated probabilities overall (see @fig-resid-outcome, @fig-resid-pearson, @fig-calibration, @fig-resid-age, and @tbl-resid-summary).

# Results
```{r}
posterior_stats <- posterior_summary$statistics %>%
  as.data.frame() %>%
  tibble::rownames_to_column("parameter")

posterior_quants <- posterior_summary$quantiles %>%
  as.data.frame() %>%
  tibble::rownames_to_column("parameter")

posterior_table <- posterior_stats %>%
  dplyr::select(parameter, Mean, SD) %>%
  left_join(
    posterior_quants %>%
      dplyr::select(parameter, `2.5%`, `50%`, `97.5%`),
    by = "parameter"
  ) %>%
  filter(
    stringr::str_detect(
      parameter,
      "^(beta_(age|tpa|thr|ems|not|time|race)|sigma_site_out)"
    )
  )


posterior_odd_ratios_table <- posterior_table %>%
  filter(stringr::str_detect(parameter, "^beta")) %>%
  mutate(
    OR_mean = exp(Mean),
    OR_low  = exp(`2.5%`),
    OR_high = exp(`97.5%`)
  ) %>%
  dplyr::select(parameter, OR_mean, OR_low, OR_high) %>%
  arrange(parameter)
```

The posterior summary Table (@tbl-posterior-table) and the (@tbl-posterior-odd-ratios-table) indicate several strong associations. Each additional year of age is associated with roughly a 6-7% decrease in the odds or a good discharge outcome (OR = 0.94), Patients arriving via EMS had about 65% lower odds of being discharged home or to  rehabilitation compared to those arriving by car (OR = 0.34) consistent with EMS patients having more severe strokes. Complications were among the strongest predictors of poor outcomes: thrombectomy complications were associated with an approximately 89% reduction in the odds of a good discharge, and tPA complications with a 75% reduction. Race differences were also noticable: African American patients had about 35% lower odds of good outcomes compared to Caucasian patients.   


Time effects provided insight into whether outcomes improved over the study period. Compared with baseline, the mid-study period and final periods were associated with roughly 20-30% higher odds of a good discharge outcome. When translated into predicted probabilities for a reference patient (female, Caucasian, median age(70), car arrival, no complications, average site), the model estimates an absolute improvement of about 2-4 percent points from baseline to the final study period. Taken together with the residual and calibration diagnostics, these findings suggest modest but consistent evidence that outcomes improved over time. 


# Conclusion

# Limitations and Future Directions

\newpage

# Appendix

## Convergence diagnostics
```{r, echo=FALSE}
#| label: tbl-ess
#| tbl-cap: "Effective sample sizes for core parameters."
#| tbl-pos: H
ess_vals <- effectiveSize(posterior_samples)
ess_table <- tibble(parameter = names(ess_vals), ess = as.numeric(ess_vals))
knitr::kable(ess_table, digits = 1)
```

```{r, echo=FALSE}
#| label: tbl-rhat
#| tbl-cap: "Gelman–Rubin PSRF for monitored parameters."
#| tbl-pos: H
psrf <- gelman.diag(posterior_samples, multivariate = FALSE)$psrf
rhat_table <- tibble(
  parameter = rownames(psrf),
  point_est = psrf[, 1],
  upper_ci = psrf[, 2]
)
knitr::kable(rhat_table, digits = 3)
```

```{r, echo=FALSE}
#| label: fig-trace
#| fig-cap: "Trace plots for selected parameters."
#| fig-pos: H
old_par <- par(mfrow = c(2, 2))
traceplot(posterior_samples[, c("beta0", "beta_age", "beta_tpa", "beta_thr")])
par(old_par)
```

## Residual diagnostics

```{r}
load("strokeStudy.RData")
x <- x %>%
  janitor::clean_names() %>%
  rename(emsvscar = em_svs_car) %>%
  mutate(
    race2 = na_if(race2, "Missing"),
    race2 = factor(race2),
    site_id = factor(site_id),
    time_stage = case_when(
      time2 %in% c("Y1Q1","Y1Q2") ~ "baseline",
      time2 %in% c("Y1Q3","Y1Q4","Y2Q1","Y2Q2") ~ "mid",
      time2 %in% c("Y2Q3","Y2Q4") ~ "final",
      TRUE ~ NA_character_
    ),
    time_stage = factor(time_stage, levels = c("baseline","mid","final"))
  )
time_stage_levels <- c("baseline","mid","final")

impute_vars <- x %>% select(
  home_or_rehab, age, gender, race2, emsvscar, pre_hosp_notify,
  had_tpa, had_thrombectomy, tpa_complic, thr_complic, site_id, time2
)

meth <- make.method(impute_vars); meth["age"] <- "pmm"
pred <- make.predictorMatrix(impute_vars); pred["age", ] <- 0
pred["age", c("gender","race2","emsvscar","pre_hosp_notify",
              "had_tpa","had_thrombectomy","tpa_complic",
              "thr_complic","site_id","time2","home_or_rehab")] <- 1
set.seed(2025)
imp <- mice(impute_vars, m = 1, maxit = 5, method = meth,
            predictorMatrix = pred, printFlag = FALSE)

comp1 <- complete(imp, 1)

comp1_design <- comp1 %>%
  mutate(
    age = as.numeric(age),
    time_stage = case_when(
      time2 %in% c("Y1Q1", "Y1Q2") ~ "baseline",
      time2 %in% c("Y1Q3", "Y1Q4", "Y2Q1", "Y2Q2") ~ "mid",
      time2 %in% c("Y2Q3", "Y2Q4") ~ "final",
      TRUE ~ NA_character_
    ),
    time_stage = factor(time_stage, levels = time_stage_levels),
    time_stage_idx = as.integer(time_stage),
    gender_num = if_else(gender == "Female", 1, 0),
    transport_num = case_when(emsvscar == 1 ~ 1,
                              emsvscar == 0 ~ 0,
                              TRUE ~ NA_real_),
    notify_num = case_when(pre_hosp_notify == "Yes" ~ 1,
                           pre_hosp_notify == "No" ~ 0,
                           TRUE ~ NA_real_),
    had_tpa_num = as.integer(had_tpa),
    had_thromb_num = as.integer(had_thrombectomy),
    tpa_comp_num = as.integer(tpa_complic),
    thr_comp_num = as.integer(thr_complic),
    home_num = as.integer(home_or_rehab),
    race_idx = as.integer(factor(race2, levels = levels(x$race2)))
  ) %>%
  drop_na(age, time_stage_idx, race_idx, transport_num, notify_num)

posterior_matrix <- as.matrix(posterior_samples)
draw_ids <- sample(seq_len(nrow(posterior_matrix)), size = min(2000, nrow(posterior_matrix)))
beta_time_cols <- grep("^beta_time", colnames(posterior_matrix), value = TRUE)
beta_race_cols <- grep("^beta_race", colnames(posterior_matrix), value = TRUE)

compute_probs <- function(draw_vec) {
  beta_time <- as.numeric(draw_vec[beta_time_cols])
  time_effect <- beta_time[comp1_design$time_stage_idx]

  race_lookup <- rep(0, length(levels(x$race2)))
  if (length(beta_race_cols) > 0) {
    for (col in beta_race_cols) {
      idx <- as.integer(gsub("beta_race\\[(\\d+)\\]", "\\1", col))
      race_lookup[idx] <- as.numeric(draw_vec[col])
    }
  }
  race_effect <- race_lookup[comp1_design$race_idx]

  eta <- as.numeric(draw_vec["beta0"]) +
    as.numeric(draw_vec["beta_age"])    * comp1_design$age +
    as.numeric(draw_vec["beta_gender"]) * comp1_design$gender_num +
    as.numeric(draw_vec["beta_ems"])    * comp1_design$transport_num +
    as.numeric(draw_vec["beta_not"])    * comp1_design$notify_num +
    as.numeric(draw_vec["beta_tpa"])    * comp1_design$had_tpa_num +
    as.numeric(draw_vec["beta_thr"])    * comp1_design$had_thromb_num +
    as.numeric(draw_vec["beta_tpaC"])   * comp1_design$tpa_comp_num +
    as.numeric(draw_vec["beta_thrC"])   * comp1_design$thr_comp_num +
    time_effect +
    race_effect

  plogis(eta)
}

pred_matrix <- sapply(draw_ids, function(idx) compute_probs(posterior_matrix[idx, ]))
posterior_mean_pred <- rowMeans(pred_matrix)

residuals_df <- comp1_design %>%
  mutate(
    pred = posterior_mean_pred,
    resid = home_num - posterior_mean_pred,
    abs_resid = abs(resid),
    outcome = factor(home_num, labels = c("Poor outcome", "Good outcome")),
    pearson = (home_num - posterior_mean_pred) / sqrt(posterior_mean_pred * (1 - posterior_mean_pred))
  )

residual_summary <- residuals_df %>%
  summarise(
    mean_resid = mean(resid),
    sd_resid = sd(resid),
    extreme = mean(abs_resid > 0.5)
  )

```{r tbl-resid-summary, echo=FALSE}
#| tbl-cap: "Summary of posterior residuals."
#| tbl-pos: H
residual_summary |> knitr::kable(digits = 3)
```

```{r fig-resid-outcome, echo=FALSE}
#| fig-cap: "Residuals by observed outcome."
#| fig-pos: H
ggplot(residuals_df, aes(x = pred, y = resid, color = outcome)) +
  geom_point(alpha = 0.25) +
  geom_hline(yintercept = 0, linetype = "dashed") +
  facet_wrap(~ outcome) +
  labs(
    title = "Residuals by Observed Outcome",
    x = "Posterior Mean Predicted Probability",
    y = "Observed - Predicted",
    color = "Outcome"
  )
```

```{r fig-resid-pearson, echo=FALSE}
#| fig-cap: "Pearson residuals vs. posterior mean predicted probability."
#| fig-pos: H
ggplot(residuals_df, aes(x = pred, y = pearson)) +
  geom_point(alpha = 0.25, color = "darkorange") +
  geom_hline(yintercept = 0, linetype = "dashed") +
  labs(
    title = "Pearson Residuals",
    x = "Posterior Mean Predicted Probability",
    y = "Pearson Residual"
  )
```

```{r fig-resid-hist, echo=FALSE}
#| fig-cap: "Distribution of posterior residuals."
#| fig-pos: H
ggplot(residuals_df, aes(x = resid)) +
  geom_histogram(bins = 40, fill = "gray70", color = "white") +
  labs(
    title = "Distribution of Posterior Residuals",
    x = "Residual",
    y = "Count"
  )
```

```{r fig-calibration, echo=FALSE}
#| fig-cap: "Bayesian calibration curve (deciles of predicted probability)."
#| fig-pos: H
bayes_calibration <- residuals_df %>%
  mutate(bin = ntile(pred, 10)) %>%
  group_by(bin) %>%
  summarise(
    mean_pred = mean(pred),
    obs_rate = mean(home_num),
    .groups = "drop"
  )

ggplot(bayes_calibration, aes(x = mean_pred, y = obs_rate)) +
  geom_point(color = "firebrick") +
  geom_line(color = "firebrick") +
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") +
  labs(
    title = "Bayesian Calibration Curve",
    x = "Posterior Mean Predicted Probability",
    y = "Observed Proportion"
  )
```

```{r fig-resid-age, echo=FALSE}
#| fig-cap: "Residuals vs. age by observed outcome."
#| fig-pos: H
ggplot(residuals_df, aes(x = age, y = resid, color = outcome)) +
  geom_point(alpha = 0.25) +
  geom_smooth(se = FALSE) +
  labs(
    title = "Residuals vs Age",
    x = "Age",
    y = "Observed - Predicted",
    color = "Outcome"
  )
```

## Posterior tables
```{r tbl-posterior-table, echo=FALSE}
#| tbl-cap: "Posterior means and 95% credible intervals."

posterior_table |> knitr::kable(digits = 3)
```

```{r tbl-posterior-odd-ratios-table, echo=FALSE}
#| tbl-cap: "Posterior odds ratios for key covariates."
posterior_odd_ratios_table |> knitr::kable(digits = 3)
```
